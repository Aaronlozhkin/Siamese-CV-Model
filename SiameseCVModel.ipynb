{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPxM7JbnGMnu"
      },
      "source": [
        "Written and developed by Aaron Lozhkin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ueOSFjRGzOF"
      },
      "source": [
        "# Load the Huggingface Snacks Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcIFyU2NHp5_",
        "outputId": "f8fd6377-d82f-41cb-c0fd-9a512965f064"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsm0f7jIGWhO"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"Matthijs/snacks\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZWcWDRH9e_"
      },
      "source": [
        "# Load Snacks Dataset into PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU8ZXVAyH4Mj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP6OcekLVrrZ"
      },
      "outputs": [],
      "source": [
        "# Helper Function to Display Images\n",
        "\n",
        "def displayTriplet(anchor, positive, negative, title=None, inverseTransform=True):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
        "\n",
        "    if not(title is None):\n",
        "        fig.suptitle(title)\n",
        "\n",
        "    if inverseTransform:\n",
        "        invtransform = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
        "                                                                      std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
        "                                                 transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
        "                                                                      std = [ 1., 1., 1. ]),\n",
        "                                                 transforms.ToPILImage()\n",
        "                                          ])\n",
        "        anchor, positive, negative = invtransform(anchor), invtransform(positive), invtransform(negative)\n",
        "\n",
        "    # Display anchor image\n",
        "    axs[0].imshow(anchor)\n",
        "    axs[0].set_title('Anchor')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    # Display positive image\n",
        "    axs[1].imshow(positive)\n",
        "    axs[1].set_title('Positive')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    # Display negative image\n",
        "    axs[2].imshow(negative)\n",
        "    axs[2].set_title('Negative')\n",
        "    axs[2].axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lAHjnalIK7P"
      },
      "outputs": [],
      "source": [
        "from datasets.packaged_modules import imagefolder\n",
        "# Create a custom Siamese Triplet Dataset class to return triplets from the snacks dataset\n",
        "\n",
        "class SiameseTripletDataset(Dataset):\n",
        "    def __init__(self, ds, width, height):\n",
        "        self.ds = ds\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.num_classes = len(set(self.ds['label']))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize((self.width, self.height)),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize to [0, 1]\n",
        "        ])\n",
        "\n",
        "        # Organize data by labels and apply transform\n",
        "        self.label_to_images = {}\n",
        "        for idx, data_point in enumerate(self.ds):\n",
        "            label = data_point['label']\n",
        "            if label not in self.label_to_images:\n",
        "                self.label_to_images[label] = []\n",
        "            self.label_to_images[label].append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.ds)\n",
        "\n",
        "    def show_images(self, idx):\n",
        "        anchor_image, positive_image, negative_image = self[idx]\n",
        "        displayTriplet(anchor_image, positive_image, negative_image)\n",
        "\n",
        "    def getImage(self, idx, transform=True):\n",
        "        if transform:\n",
        "            return self.transform(self.ds[idx]['image']), self.ds[idx]['label']\n",
        "        return self.ds[idx]['image'], self.ds[idx]['label']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_image, anchor_label = self.ds[idx]['image'], self.ds[idx]['label']\n",
        "\n",
        "        # Generate a positive pair with the same label\n",
        "        positive_idx = random.choice(self.label_to_images[anchor_label])\n",
        "        positive_image, positive_label = self.ds[positive_idx]['image'], self.ds[positive_idx]['label']\n",
        "\n",
        "        # Generate a negative pair with a different label\n",
        "        labels = list(self.label_to_images.keys())\n",
        "        labels.remove(anchor_label)\n",
        "        negative_label = random.choice(labels)\n",
        "        assert (negative_label != anchor_label)\n",
        "        negative_idx = random.choice(self.label_to_images[negative_label])\n",
        "        negative_image, negative_label = self.ds[negative_idx]['image'], self.ds[negative_idx]['label']\n",
        "\n",
        "        anchor_image = self.transform(anchor_image)\n",
        "        positive_image = self.transform(positive_image)\n",
        "        negative_image = self.transform(negative_image)\n",
        "\n",
        "        return anchor_image, positive_image, negative_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFelYd4hQ0i8"
      },
      "outputs": [],
      "source": [
        "# We resize the images to (244, 244) similar to what is used by ResNet\n",
        "\n",
        "width, height = 224, 224\n",
        "\n",
        "train_dataset = SiameseTripletDataset(ds=ds['train'], width=width, height=height)\n",
        "test_dataset = SiameseTripletDataset(ds=ds['test'], width=width, height=height)\n",
        "validation_dataset = SiameseTripletDataset(ds=ds['validation'], width=width, height=height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv_Us4svTKtr"
      },
      "source": [
        "## Visualize 10 Anchor, Positive, and Negative image triplets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPMQN3w8RT1Y"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "for i in range(10):\n",
        "  idx = random.randint(0, len(train_dataset))\n",
        "  train_dataset.show_images(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsMZAfQOQwF7"
      },
      "source": [
        "# Load ResNet Model and Build Siamese Network with Triplet Loss\n",
        "Pre-trained ResNet model utilized for image embedding architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zln7ch5bT-UC"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from transformers import AutoFeatureExtractor, AutoModel\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Use a pre-trained ResNet model from Hugging Face\n",
        "        self.resnet_model = AutoModel.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "        # Fully connected layers for embedding\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "\n",
        "            nn.Linear(512, self.embedding_dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        # Forward pass for one input\n",
        "        x = self.resnet_model(x)\n",
        "        x = x.pooler_output.squeeze()\n",
        "\n",
        "        if len(x.shape) == 1:\n",
        "          # If it's a single input add a batch dimension\n",
        "          x = x.unsqueeze(0)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        # Forward pass for anchor, positive, and negative samples\n",
        "        output_anchor = self.forward_one(anchor)\n",
        "        output_positive = self.forward_one(positive)\n",
        "        output_negative = self.forward_one(negative)\n",
        "        return output_anchor, output_positive, output_negative\n",
        "\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, margin):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
        "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
        "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
        "        return losses.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0Q0slBifDMy"
      },
      "outputs": [],
      "source": [
        "# Create dataloaders for training and validation\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlcGID7r4iYI"
      },
      "source": [
        "# Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOR07ZK-bUkg"
      },
      "outputs": [],
      "source": [
        "# Load the saved model from google drive\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1T2BXHH4M2ZUXYBpTnWWiaAv18JZbxXsS\" -O siamese_triplet_model_cache.pth && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61eVUt-N4kvi"
      },
      "outputs": [],
      "source": [
        "siamese_net = SiameseNetwork().to(device)\n",
        "if torch.cuda.is_available():\n",
        "  siamese_net.load_state_dict(torch.load(\"siamese_triplet_model_test.pth\"))\n",
        "else:\n",
        "  print(\"WARNING: Model will run extremely slow on cpu. If on colab, go to Runtime->Change Runtime Type->Hardware Accelerator->GPU.\")\n",
        "  siamese_net.load_state_dict(torch.load(\"/content/siamese_triplet_model_cache.pth\", map_location=torch.device('cpu')))\n",
        "siamese_net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qOl6UQezDWT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "data_iter = iter(validation_loader)\n",
        "\n",
        "# Get a random batch from the validation dataset\n",
        "batch = next(data_iter)\n",
        "\n",
        "anchor, positive, negative = batch\n",
        "anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "# Compute embeddings using the Siamese Network\n",
        "anchor_embedding, positive_embedding, negative_embedding = siamese_net.forward(anchor, positive, negative)\n",
        "\n",
        "normalized_anchor_embedding = torch.nn.functional.normalize(anchor_embedding, p=2, dim=1)\n",
        "normalized_positive_embedding = torch.nn.functional.normalize(positive_embedding, p=2, dim=1)\n",
        "normalized_negative_embedding = torch.nn.functional.normalize(negative_embedding, p=2, dim=1)\n",
        "\n",
        "# Compute the disimilarity score using Euclidean distance\n",
        "# disimilarity_positive = F.pairwise_distance(normalized_anchor_embedding, normalized_positive_embedding, keepdim=True)\n",
        "# disimilarity_negative = F.pairwise_distance(normalized_anchor_embedding, normalized_negative_embedding, keepdim=True)\n",
        "\n",
        "# Compute the similarity score using cosine similarity\n",
        "similarity_positive = F.cosine_similarity(normalized_anchor_embedding, normalized_positive_embedding)\n",
        "similarity_negative = F.cosine_similarity(normalized_anchor_embedding, normalized_negative_embedding)\n",
        "\n",
        "for i in range(10):\n",
        "  displayTriplet(anchor[i], positive[i], negative[i], title= \"Validation Triplet \" + str(i+1) + \"\\n\" +\n",
        "               f\"Positive similarity Score: {similarity_positive[i].item():.4f}\" + \"\\t\".expandtabs() +\n",
        "               f\"Negative similarity Score: {similarity_negative[i].item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK0unQX-Vrrc"
      },
      "source": [
        "# Reverse Image Search Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzQfH-TSVrrc"
      },
      "outputs": [],
      "source": [
        "# Utilize the train dataset to create a reverse image search engine.\n",
        "# Embed the entire train dataset\n",
        "\n",
        "siamese_net.eval()\n",
        "\n",
        "train_embeddings = []\n",
        "\n",
        "for i in tqdm(range(len(train_dataset)), desc=\"Generating Train Embeddings\"):\n",
        "    image = train_dataset.getImage(i, transform=True)[0]\n",
        "    image = image.unsqueeze(0).to(device)\n",
        "    train_embeddings.append(siamese_net.forward_one(image).detach().to('cpu'))\n",
        "\n",
        "del image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEFqSYXJVrrc"
      },
      "outputs": [],
      "source": [
        "# Take a query image from the test dataset\n",
        "# Adjust the index to query for different types of images\n",
        "\n",
        "query_idx = 99\n",
        "\n",
        "query_image_initial = test_dataset.getImage(query_idx, transform=False)[0]\n",
        "print(\"Query Image\")\n",
        "display(query_image_initial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz54AzdKVrrc"
      },
      "outputs": [],
      "source": [
        "# Display the top 20 most similar images using the Siamese Network\n",
        "\n",
        "\n",
        "query_image = test_dataset.getImage(query_idx, transform=True)[0]\n",
        "\n",
        "# Embed the query image\n",
        "with torch.no_grad():\n",
        "    query_embedding = siamese_net.forward_one(query_image.unsqueeze(0).to(device)).detach().cpu()\n",
        "\n",
        "# Calculate distances (cosine similarity)\n",
        "similarities = []\n",
        "for idx, dataset_embedding in enumerate(train_embeddings):\n",
        "    # Calculate cosine similarity\n",
        "    similarity = F.cosine_similarity(query_embedding, dataset_embedding)\n",
        "    similarities.append((idx, similarity.detach().cpu().item()))\n",
        "\n",
        "# Sort images by similarity\n",
        "similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get the top N similar images\n",
        "top_n = 20\n",
        "\n",
        "# Create a grid of subplots\n",
        "n_rows = 5\n",
        "n_cols = 4\n",
        "fig, axs = plt.subplots(n_rows, n_cols, figsize=(30, 50))\n",
        "\n",
        "# Get the top N similar images and their similarity scores\n",
        "top_similar_images = [train_dataset.getImage(idx, transform=False)[0] for idx, _ in similarities[:top_n]]\n",
        "top_similarity_scores = [similarity for _, similarity in similarities[:top_n]]\n",
        "\n",
        "# Display the top N similar images in the grid\n",
        "for i in range(len(top_similar_images)):\n",
        "    row = i // n_cols\n",
        "    col = i % n_cols\n",
        "    ax = axs[row, col]\n",
        "\n",
        "    # Display image\n",
        "    ax.imshow(top_similar_images[i])\n",
        "    ax.set_title(f'Search Result {i+1}' + f', Similarity Score: {top_similarity_scores[i]:.4f}', fontsize=12)\n",
        "    ax.axis('off')\n",
        "\n",
        "# Remove empty subplots if top_n is less than n_rows * n_cols\n",
        "for i in range(len(top_similar_images), n_rows * n_cols):\n",
        "    row = i // n_cols\n",
        "    col = i % n_cols\n",
        "    axs[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFKZ8lpddVkp"
      },
      "source": [
        "# Model Training Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oUsfIC_fvoq"
      },
      "outputs": [],
      "source": [
        "# Create Siamese network and optimizer, and move them to CUDA if available\n",
        "siamese_net = SiameseNetwork().to(device)\n",
        "optimizer = optim.Adam(siamese_net.parameters(), lr=0.0001)\n",
        "\n",
        "# Define triplet loss function\n",
        "criterion = TripletLoss(margin=1.0)\n",
        "loss_list = []\n",
        "validation_loss_list = []\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Create a tqdm progress bar for the training loader\n",
        "    train_loader_iter = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
        "    for batch in train_loader_iter:\n",
        "        anchor, positive, negative = [th.to(device) for th in batch]\n",
        "        optimizer.zero_grad()\n",
        "        output_anchor, output_positive, output_negative = siamese_net(anchor, positive, negative)\n",
        "        loss = criterion(output_anchor, output_positive, output_negative)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loader_iter.set_postfix({'Loss': loss.item()})\n",
        "\n",
        "    # Validation loop\n",
        "    with torch.no_grad():\n",
        "        total_validation_loss = 0.0\n",
        "        num_batches = 0\n",
        "        for batch in validation_loader:\n",
        "            anchor_val, positive_val, negative_val = [th.to(device) for th in batch]\n",
        "            output_anchor_val, output_positive_val, output_negative_val = siamese_net(anchor_val, positive_val, negative_val)\n",
        "            validation_loss = criterion(output_anchor_val, output_positive_val, output_negative_val)\n",
        "            total_validation_loss += validation_loss.item()\n",
        "            num_batches += 1\n",
        "        average_validation_loss = total_validation_loss / num_batches\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}, Validation Loss: {average_validation_loss}')\n",
        "    loss_list.append(loss.item())\n",
        "    validation_loss_list.append(average_validation_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPNucCZIVrrb"
      },
      "outputs": [],
      "source": [
        "# Let's visualize the loss over time. Since we were able to utilize ResNet, we didn't have to train for many epochs.\n",
        "epochs = range(1, len(loss_list) + 1)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_list, label='Training Loss', marker='o', linestyle='-')\n",
        "plt.plot(epochs, validation_loss_list, label='Validation Loss', marker='o', linestyle='-')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DfqYdMlx2Ov"
      },
      "source": [
        "## Observe Test Set Accuracy\n",
        "Accuracy is measured by the amount of triplets the network correctly identified as positive and negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAU7uc3YyC2b"
      },
      "outputs": [],
      "source": [
        "from datasets.utils.version import total_ordering\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize variables for accuracy computation\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        anchor, positive, negative = [th.to(device) for th in batch]\n",
        "\n",
        "        # Compute embeddings for anchor, positive, and negative samples\n",
        "        anchor_embedding = siamese_net.forward_one(anchor)\n",
        "        positive_embedding = siamese_net.forward_one(positive)\n",
        "        negative_embedding = siamese_net.forward_one(negative)\n",
        "\n",
        "        normalized_anchor_embedding = torch.nn.functional.normalize(anchor_embedding, p=2, dim=1)\n",
        "        normalized_positive_embedding = torch.nn.functional.normalize(positive_embedding, p=2, dim=1)\n",
        "        normalized_negative_embedding = torch.nn.functional.normalize(negative_embedding, p=2, dim=1)\n",
        "\n",
        "        # Compute the similarity scores (e.g., cosine similarities)\n",
        "        similarity_positive = torch.cosine_similarity(normalized_anchor_embedding, normalized_positive_embedding, dim=1)\n",
        "        similarity_negative = torch.cosine_similarity(normalized_anchor_embedding, normalized_negative_embedding, dim=1)\n",
        "\n",
        "        is_correct_positive = similarity_positive > similarity_negative\n",
        "        correct += is_correct_positive.sum().item()\n",
        "        total += anchor.size(0)\n",
        "\n",
        "# Calculate accuracy for positive and negative pairs separately\n",
        "accuracy = correct / total * 100.0\n",
        "\n",
        "print(f'Overall Test Accuracy: {accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs-obI-A4E1x"
      },
      "source": [
        "## Save Model For Later Use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NcNbNOU35uO"
      },
      "outputs": [],
      "source": [
        "torch.save(siamese_net.state_dict(), 'siamese_triplet_model_test.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
